-------------------------------------------------------------------

**ANALISI ALGORITMI**
---
*Analisi della complessit√†*
	Per *analisi di un algoritmo* si intende la valutazione delle risorse richieste da un algoritmo per risolvere un problema dato.
	Per *risorse* intendiamo essenzialmente:
		**Tempo** *T(n)*
			Necessario all'algoritmo per produrre l'output richiesto.
		**Memoria** *S(n)*
			Utilizzata dall'algoritmo durante la sua esecuzione
	*Tempo d'Esecuzione*
		Il tempo d'esecuzione dipende:
			1) Dal linguaggio macchina usato dal computer
			2) Dall'eseguibile generato
			3) Dalla dimensione dell'input
			4) Da come √® fatto l'input
			5) Dal numero di operazioni eseguite
		Useremo le costanti asintotiche $O,\Theta, \Omega$ per misurare il tempo d'esecuzione, a meno di una costante moltiplicativa. Per dimensioni di input molto grandi, le costanti influenzano in modo irrilevante il tempo d'esecuzione.
	*Operazioni Elementari*
		Alcune operazioni svolte dai processi sono dette *elementari*, perch√® sono rapide ed economiche.
		Esempi sono:
			1) Addizione e moltiplicazione di numeri *piccoli*
			2) Confronto fra numeri
			3) Spostamento di un puntatore
		Assumiamo che ogni operazione elementare richieda un *tempo costante*, che rappresenta la nostra unit√† elementare $O(1)$.
	*Dimensione Input*
		Il tempo d'esecuzione dipende dalla *taglia* dell'input.
		Per taglia si intende:
			1) Il numero di bit necessari a rappresentarlo (*criterio di costo **logaritmico***)
			2) Il numero degli elementi che lo compongono (*criterio di costo **uniforme***)
		Tali criteri coincidono, a meno di un fattore moltiplicativo costante, nell'ipotesi che *ogni istruzione del computer richieda un'unit√† elementare di tempo*, e che ogni elemento *richieda una parola di memoria*.
	*Forma Input*
		La forma dell'input pu√≤ influenzare la complessit√† dell'algoritmo. Ad esempio, ordinare N elementi in un array √® pi√π veloce *se l'array √® quasi ordinato*.
		Nell'analisi solitamente si analizzer√†:
			1) Caso migliore (*ordinato*)
			2) Caso medio (*semi-ordinato*)
			3) Caso peggiore (*Non ordinato*)
	*Calcolo complessit√†*
		Useremo alcune regole:
			1) Il costo di istruzioni semplici, come assegnazione o lettura/scrittura di variabili √® $O(1)$
			2) Il costo di operazioni *if/then/else* √® pari al tempo *per il confronto*, pi√π il costo dell'alternativa pi√π costosa.
			3) Il costo dei loop √® pari *alla somma del costo di ogni iterazione*

----------------------------------------------
**ALGORITMI ORDINAMENTO**
---
*Insertion Sort*
	L'ordinamento √® un'operazione fondamentale in informatica, e pertanto sono stati sviluppati un gran numero di algoritmi di ordinamento.
	L'Insertion Sort √® quello pi√π semplice, ed √® efficente con un input di piccola taglia.
	L'algoritmo ordina *tutti gli elementi nel sottoinsieme di sinistra*, mentre prende *uno alla volta* gli elementi *nel sottoinsieme di destra* (la restante parte dell'array).
```c++
For j<-2 to A.length 
	key<-A[j]
	// Inserisce A[j] nella sequenza ordinata ùê¥[1 ‚Ä¶ ùëó ‚àí 1]
	i<-j-1
	While (i> 0 and A[i] > key)
		A[i+1]<-A[i]
		i<-i-1
	A[i+1]<-key
```
Ogni elemento, *dal 2¬∞ all'ultimo*, viene estratto, e confrontato con tutti i precedenti, che *slittano in avanti* se pi√π grandi. Alla fine, l'elemento entra *nella locazione libera*.

**Invariante di ciclo**
---
*Invariante*
	Utilizziamo le *invarianti* per aiutarci a capire perch√® un algoritmo √® corretto. Dobbiamo dimostrare tre cose su un'invariante:
		1) **Inizializzazione** : *√® vera prima della 1¬∞ iterazione*
		2) **Conservazione** : se √® vera prima di un'iterazione, *rimane vera prima della successiva iterazione*
		3) **Conclusione** : Quando il ciclo termina, l'invariante *fornisce un utile propriet√†* che ci aiuta a dimostrare la correttezza dell'algoritmo.
	*Insertion Sort*
		1) **Inizializzazione** :
			Prima della prima iterazione, quando j=2, abbiamo che il sottoarray $A[1,...,j-1]$ √® ordinato, essendo formato dal singolo elemento $A[1]$, che √® l'elemento originale in $A[1]$.
		2) **Conservazione**:
			Il corpo del *for* opera spostando $A[j-1]$,$A[j-2]$,... *di una posizione verso destra*, finch√® non trova la posizione adatta per $A[j]$, dove lo inserir√†.
			Il sottoarray $A[1,...,j]$ √® ordinato, ed √® formato dagli stessi elementi che originariamente erano presenti in $A[1,...,j]$. Perci√≤, *l'incremento di j per la successiva iterazione **preserva l'invariante***.
		3) **Conclusione**:
			La condizione che determina la fine del ciclo √® $j>A.length=n$. Poich√® ad ogni iterazione j aumenta di 1, alla fine del ciclo si avr√† $j=n+1$.
			Sostituendo j con n+1, otteniamo che il sottoarray $A[1,...,n]$ √® formato dagli elementi *ordinati* che originariamente erano in $A[1,...,n]$, che per√≤ *√® l'intero array*, che quindi √® ordinato.
		Pertanto, *l'algoritmo √® corretto*.

--------------------------------------------
